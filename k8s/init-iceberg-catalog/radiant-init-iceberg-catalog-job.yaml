apiVersion: batch/v1
kind: Job
metadata:
  name: radiant-init-iceberg-catalog-job
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: spark
          image: apache/spark:3.5.6
          command: ["/opt/spark/bin/spark-submit"]
          args:
            - --master
            - local[*]
            - --conf
            - spark.driver.extraJavaOptions=-Divy.cache.dir=/tmp -Divy.home=/tmp
            - --conf
            - spark.executor.extraJavaOptions=-Divy.cache.dir=/tmp -Divy.home=/tmp
            - --conf
            - spark.hadoop.fs.s3a.endpoint=http://radiant-minio:9000
            - --conf
            - spark.hadoop.fs.s3a.path.style.access=true
            - --conf
            - spark.hadoop.fs.s3a.access.key=admin
            - --conf
            - spark.hadoop.fs.s3a.secret.key=password
            - --conf
            - spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
            - --conf
            - spark.hadoop.fs.s3a.endpoint=http://radiant-minio:9000
            - --conf
            - spark.hadoop.fs.s3a.path.style.access=true
            - --conf
            - spark.hadoop.fs.s3a.access.key=admin
            - --conf
            - spark.hadoop.fs.s3a.secret.key=password
            - --conf
            - spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
            - --conf
            - spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
            - --conf
            - spark.sql.catalog.iceberg=org.apache.iceberg.spark.SparkCatalog
            - --conf
            - spark.sql.catalog.iceberg.type=rest
            - --conf
            - spark.sql.catalog.iceberg.uri=http://radiant-iceberg-rest:8181
            - --conf
            - spark.sql.catalog.iceberg.warehouse=s3a://warehouse
            - --conf
            - spark.sql.catalog.iceberg.token=mysecret
            - --conf
            - spark.sql.catalog.iceberg.io-impl=org.apache.iceberg.aws.s3.S3FileIO
            - --conf
            - spark.sql.catalog.iceberg.s3.endpoint=http://radiant-minio:9000
            - --conf
            - spark.sql.catalog.iceberg.s3.path-style-access=true
            - --conf
            - spark.sql.catalog.iceberg.s3.access-key-id=admin
            - --conf
            - spark.sql.catalog.iceberg.s3.secret-access-key=password
            - --packages
            - org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.9.2,org.apache.iceberg:iceberg-aws-bundle:1.9.2,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.367
            - /app/copy_parquet.py
          volumeMounts:
            - name: radiant-init-iceberg-catalog-spark-job-script
              mountPath: /app
              readOnly: true
          env:
            # S3 / MinIO config
            - name: AWS_ACCESS_KEY_ID
              value: "admin"
            - name: AWS_SECRET_ACCESS_KEY
              value: "password"
            - name: AWS_REGION
              value: "us-east-1"

      volumes:
        - name: radiant-init-iceberg-catalog-spark-job-script
          configMap:
            name: radiant-init-iceberg-catalog-spark-job-script